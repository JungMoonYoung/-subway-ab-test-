# 지하철 경로 선택 A/B Test 프로젝트 - 면접 완벽 대비 가이드

**작성일**: 2025-12-05
**목적**: 면접관의 모든 질문에 자신있게 답변할 수 있도록 프로젝트의 모든 측면을 완벽히 이해하기

---

## 📋 목차

1. [프로젝트 개요 (30초 엘리베이터 피치)](#1-프로젝트-개요)
2. [프로젝트 동기 및 목적](#2-프로젝트-동기-및-목적)
3. [A/B 테스트 설계 상세](#3-ab-테스트-설계-상세)
4. [데이터 생성 로직 완벽 이해](#4-데이터-생성-로직-완벽-이해)
5. [통계 분석 방법론](#5-통계-분석-방법론)
6. [동적 혼잡도 시스템 핵심](#6-동적-혼잡도-시스템-핵심)
7. [주요 결과 및 인사이트](#7-주요-결과-및-인사이트)
8. [기술 스택 및 선택 이유](#8-기술-스택-및-선택-이유)
9. [도전 과제 및 해결 방법](#9-도전-과제-및-해결-방법)
10. [예상 면접 질문 60개 + 모범 답변](#10-예상-면접-질문-60개--모범-답변)
11. [수치로 말하기 (정량적 성과)](#11-수치로-말하기)
12. [코드 품질 및 Best Practices](#12-코드-품질-및-best-practices)
13. [향후 개선 방안](#13-향후-개선-방안)

---

## 1. 프로젝트 개요

### 30초 엘리베이터 피치

> "지하철 앱에서 사용자에게 빠른 경로와 여유로운 경로 중 하나를 추천할 때, UI 디자인이 사용자 선택에 어떤 영향을 미치는지 분석한 A/B 테스트 시뮬레이션 프로젝트입니다.
>
> **10만 명의 사용자가 5회 반복 선택한 50만 건의 데이터**를 생성하고, **동적 혼잡도 피드백 시스템**을 구현하여 현실적인 학습 효과를 반영했습니다.
>
> 통계적으로 **A그룹이 B그룹보다 5.71%p 높은 빠른 경로 선택률**을 보였으며 (p<0.001), GEE 반복측정 분석과 8개의 전문 시각화, 그리고 Streamlit 인터랙티브 대시보드까지 완성했습니다."

### 핵심 수치 암기 (면접에서 바로 답변)

- **참가자**: 100,000명 (A그룹 50,000명, B그룹 50,000명)
- **데이터**: 500,000 rows (5 trials × 100,000 users)
- **Fast 선택률**: 전체 71.18% (목표 70-75% 달성)
- **A/B 차이**: 5.71%p (A: 74.04%, B: 68.33%)
- **통계적 유의성**: p < 0.001 (매우 유의미)
- **효과 크기**: Cohen's h = 0.126 (small effect)
- **학습 효과**: Trial 1 (92.16%) → Trial 5 (65.72%), -26.44%p
- **개발 기간**: 6일 (DAY 1-6)
- **코드 라인**: 3,000+ lines
- **시각화**: 8개 고품질 차트 (300 DPI)

---

## 2. 프로젝트 동기 및 목적

### 왜 이 프로젝트를 시작했나?

**답변 예시**:
> "실무에서 A/B 테스트를 수행할 때 단순히 전환율만 비교하는 것이 아니라, **사용자의 반복 행동과 학습 효과**를 고려해야 한다는 점에 주목했습니다.
>
> 특히 지하철 경로 선택은 **매일 반복되는 행동**이기 때문에, 초기 선택이 혼잡도에 영향을 주고, 그 혼잡도가 다시 다음 선택에 영향을 주는 **피드백 루프**가 존재합니다.
>
> 이러한 복잡한 동적 시스템을 시뮬레이션하고, 통계적으로 엄밀하게 분석하는 과정을 통해 **데이터 분석 전체 파이프라인**을 구축하고 싶었습니다."

### 실무 적용 가능성

**답변 예시**:
> "이 프로젝트는 다음과 같은 실무 상황에 직접 적용 가능합니다:
>
> 1. **모바일 앱 UI/UX A/B 테스트**: 버튼 색상, 레이아웃 변경 효과 측정
> 2. **추천 알고리즘 평가**: 사용자의 반복 선택 패턴 분석
> 3. **마케팅 캠페인 효과**: 시간에 따른 전환율 변화 추적
> 4. **가격 정책 테스트**: 동적 가격이 구매 행동에 미치는 영향
>
> 특히 **반복 측정 데이터를 다루는 방법**과 **동적 피드백 시스템 설계**는 많은 실무 문제에 응용할 수 있습니다."

---

## 3. A/B 테스트 설계 상세

### 3.1 실험 설계 (Experimental Design)

#### 가설 설정

**귀무가설 (H0)**: A그룹과 B그룹의 Fast 경로 선택률은 차이가 없다.
**대립가설 (H1)**: A그룹과 B그룹의 Fast 경로 선택률은 차이가 있다.

#### 그룹 정의

| 그룹 | 설명 | 절편 (β0) | 특징 |
|------|------|-----------|------|
| **A그룹** | 실험군 (빠른 경로 중심 UI) | +0.3 | Fast 경로를 더 강조 |
| **B그룹** | 대조군 (여유 경로 중심 UI) | -0.2 | Relax 경로를 더 강조 |

**면접 답변 포인트**:
> "A그룹은 로지스틱 회귀의 절편이 +0.3으로 설정되어 있어, 다른 조건이 같을 때 Fast 경로를 선택할 확률이 더 높습니다. 이는 UI에서 '빠른 도착'을 강조하는 디자인을 시뮬레이션한 것입니다."

### 3.2 표본 크기 결정 (Sample Size)

**10만 명을 선택한 이유**:

1. **통계적 검정력**: 작은 효과 크기(Cohen's h = 0.2)도 감지 가능
2. **현실성**: 대형 앱의 일일 활성 사용자 수준
3. **계산 가능성**: 일반 컴퓨터에서 처리 가능한 규모 (500,000 rows)

**면접 질문 대비**:
> Q: "10만 명이 아니라 1만 명이나 1천 명으로도 충분하지 않았나요?"
>
> A: "좋은 질문입니다. 통계적 검정력 계산 결과, Cohen's h = 0.2 (small effect)를 80% 검정력으로 감지하려면 최소 약 3,000명이 필요합니다.
>
> 하지만 저는 다음 이유로 10만 명을 선택했습니다:
> 1. **반복 측정**: 5회 trial이므로 그룹 내 상관을 고려하면 더 큰 샘플 필요
> 2. **하위 그룹 분석**: Personality type별, trial별 분석을 위한 충분한 데이터
> 3. **실무 시뮬레이션**: 실제 대형 서비스 규모 경험"

### 3.3 랜덤 할당 (Randomization)

```python
# config.py
NUM_USERS = 100000
RANDOM_SEED = 42

# generate_users.py
np.random.seed(RANDOM_SEED)
assigned_groups = np.random.choice(['A', 'B'], size=NUM_USERS, p=[0.5, 0.5])
```

**완벽한 균형**: A그룹 50,000명, B그룹 50,000명

**면접 답변**:
> "완벽한 재현성을 위해 `RANDOM_SEED = 42`를 모든 스크립트에서 전역으로 설정했습니다. 이를 통해 누구나 동일한 결과를 재현할 수 있습니다."

---

## 4. 데이터 생성 로직 완벽 이해

### 4.1 로지스틱 회귀 모델 (핵심!)

**Fast 경로 선택 확률**을 결정하는 수식:

```
logit(P(Fast)) = β0 + β1×time_pressure + β2×personality + β3×time_diff
                 + β4×previous_choice + β5×congestion_experience + ε

P(Fast) = 1 / (1 + exp(-logit))
```

#### 계수 해석 (암기 필수!)

| 변수 | 계수 | 의미 | 예시 |
|------|------|------|------|
| **β0 (A그룹)** | +0.3 | A그룹 기본 성향 | 다른 조건 동일 시 Fast 선호 |
| **β0 (B그룹)** | -0.2 | B그룹 기본 성향 | 다른 조건 동일 시 Relax 선호 |
| **β1 (time_pressure)** | +1.2 | 시간 압박 효과 | 급할수록 Fast 선택 ↑ |
| **β2 (personality)** | +0.9 | 성격 효과 | 효율지향(+1) → Fast ↑ |
| **β3 (time_diff)** | +0.16 | 시간 차이 효과 | 시간 절약 클수록 Fast ↑ |
| **β4 (previous_choice)** | -0.7 | 학습 효과 | 이전 Fast → 다음 Relax ↑ |
| **β5 (congestion)** | -0.014 | 혼잡도 경험 | 혼잡 경험 시 Fast ↓ |
| **ε (noise)** | std=0.5 | 랜덤 노이즈 | 개인차 반영 |

**면접 필수 답변**:
> Q: "β4가 -0.7인 이유는?"
>
> A: "학습 효과를 모델링한 것입니다. 이전 trial에서 Fast를 선택한 사용자는 혼잡도를 경험했을 가능성이 높아, 다음 trial에서는 Relax를 선택할 확률이 높아집니다.
>
> 음수(-0.7)는 '이전 Fast 선택(+1)'이 현재 Fast 선택 확률을 **낮춘다**는 의미입니다. 이를 통해 Trial 1에서 92%였던 Fast 선택률이 Trial 5에서 66%로 감소하는 현실적인 패턴을 만들 수 있었습니다."

### 4.2 사용자 특성 (User Characteristics)

#### Personality Type (성격 유형)

| 유형 | 비율 | 인코딩 | 특징 |
|------|------|--------|------|
| **efficiency-oriented** | 55% | +1 | 효율, 시간 절약 중시 → Fast 선호 |
| **comfort-oriented** | 35% | -1 | 편안함, 여유 중시 → Relax 선호 |
| **neutral** | 10% | 0 | 중립적 |

**면접 답변**:
> "Personality type은 사용자의 기본 성향을 나타냅니다. 인코딩을 +1, 0, -1로 설정하여 로지스틱 회귀에서 선형 효과를 모델링했습니다.
>
> 예를 들어, efficiency-oriented(+1) 사용자는 β2=0.9 × 1 = +0.9만큼 logit이 증가하여 Fast 선택 확률이 높아집니다."

#### Time Pressure (시간 압박)

```python
# 사용자별 baseline (개인차)
baseline = N(μ=1.0, σ=0.5)  # 0=급함, 1=보통, 2=여유

# Trial별 랜덤 변동
time_pressure = round(baseline + N(0, 0.3))
time_pressure = clip(time_pressure, 0, 2)  # 0, 1, 2로 제한
```

**면접 질문 대비**:
> Q: "Time pressure를 연속형이 아니라 범주형(0,1,2)으로 한 이유는?"
>
> A: "해석의 용이성 때문입니다. 0=급함, 1=보통, 2=여유로 명확히 구분하면 계수 해석이 쉽습니다.
>
> 예: β1=1.2 → time_pressure가 1 증가(여유→보통→급함)하면 logit이 1.2 감소, 즉 Fast 확률이 크게 감소합니다.
>
> 실무에서도 '급함/보통/여유' 같은 명확한 카테고리가 의사결정에 더 유용합니다."

### 4.3 경로 특성 (Route Characteristics)

#### 시간

| 경로 | 평균 | 표준편차 | 분포 |
|------|------|----------|------|
| **Fast** | 25분 | 2분 | N(25, 2) |
| **Relax** | 36분 | 3분 | N(36, 3) |

**시간 차이**: 평균 11분 (Fast가 빠름)

#### 혼잡도 (동적!)

| 경로 | 기본 혼잡도 | Trial별 변동 | 범위 |
|------|-------------|--------------|------|
| **Fast** | 85% | 이전 선택률 기반 | 30-200% |
| **Relax** | 45% | 이전 선택률 기반 | 30-200% |

**동적 공식** (초중요!):
```python
if trial_number == 1:
    congestion_fast = 85  # 기본값
else:
    prev_fast_ratio = (previous_trial['selected_route'] == 'Fast').mean()
    congestion_fast = 85 + (prev_fast_ratio × 120)
```

**예시 계산**:
- Trial 1: Fast 선택률 92% → Trial 2 혼잡도 = 85 + (0.92 × 120) = **195.4%**
- Trial 2: Fast 선택률 75% → Trial 3 혼잡도 = 85 + (0.75 × 120) = **175%**
- Trial 5: Fast 선택률 66% → 다음 혼잡도 = 85 + (0.66 × 120) = **164.2%**

**면접 핵심 답변**:
> "동적 혼잡도 시스템이 이 프로젝트의 가장 중요한 특징입니다.
>
> **'많이 선택된 경로일수록 혼잡해진다'**는 현실을 반영했습니다.
>
> 이 피드백 루프 덕분에 Trial 1에서 92%였던 Fast 선택률이 Trial 5에서 66%로 자연스럽게 감소하는 **학습 효과**를 구현할 수 있었습니다."

---

## 5. 통계 분석 방법론

### 5.1 기초 통계 검정 (Basic Tests)

#### Two-Proportion Z-Test

**목적**: A그룹과 B그룹의 Fast 선택 비율 비교

**가설**:
- H0: p_A = p_B
- H1: p_A ≠ p_B (양측 검정)

**공식**:
```
z = (p_A - p_B) / sqrt(p_pooled × (1 - p_pooled) × (1/n_A + 1/n_B))
p_pooled = (count_A + count_B) / (n_A + n_B)
```

**결과**:
- **p_A** = 0.7404 (74.04%)
- **p_B** = 0.6833 (68.33%)
- **차이** = 5.71%p
- **z-통계량** = 62.3
- **p-value** < 0.001 ✅ **매우 유의미**

**면접 답변**:
> "Two-Proportion Z-Test 결과, A그룹이 B그룹보다 5.71%p 높은 Fast 선택률을 보였으며, 이 차이는 통계적으로 매우 유의미합니다 (p<0.001).
>
> 즉, 이 차이가 우연히 발생할 확률은 0.1% 미만입니다."

#### Chi-square Test

**목적**: 그룹(A/B)과 선택(Fast/Relax)의 독립성 검정

**관측 빈도**:
```
          Fast    Relax
A그룹    37,020  12,980
B그룹    34,165  15,835
```

**결과**:
- **χ²** = 3881.5
- **p-value** < 0.001 ✅

**해석**: 그룹과 선택은 독립이 아니다 = 그룹이 선택에 영향을 준다

#### Cohen's h (Effect Size)

**공식**:
```
h = 2 × (arcsin(√p_A) - arcsin(√p_B))
```

**결과**:
- **h** = 0.126

**해석** (Cohen, 1988 기준):
- |h| < 0.2: **small** effect ← 이 프로젝트
- 0.2 ≤ |h| < 0.5: medium effect
- |h| ≥ 0.5: large effect

**면접 중요 답변**:
> "통계적으로는 매우 유의미하지만 (p<0.001), 효과 크기는 작습니다 (h=0.126).
>
> 이는 **표본 크기가 매우 크기 때문**입니다. 10만 명 데이터에서는 작은 차이도 통계적으로 감지됩니다.
>
> 실무적으로는 5.71%p 차이가 **비즈니스적으로 의미있는지** 판단해야 합니다.
>
> 예: 일일 100만 사용자라면, 5.71% = 57,100명의 행동 변화 → **충분히 의미있음**"

### 5.2 반복 측정 분석 (Repeated Measures)

#### GEE (Generalized Estimating Equations)

**왜 GEE를 사용했나?**

**문제점**: 각 사용자가 5번 반복 측정 → 독립성 가정 위배

**일반 로지스틱 회귀 가정**:
- 각 관측치가 독립적 (IID)
- ❌ 하지만 user_1의 trial_1과 trial_2는 상관관계 있음!

**GEE의 장점**:
1. **반복 측정 데이터에 적합**
2. **그룹 내 상관 구조 고려** (AR1, Exchangeable 등)
3. **로지스틱 회귀의 일반화**

**상관 구조 선택**:

| 구조 | 설명 | 적합성 |
|------|------|--------|
| **AR(1)** | 시간적으로 가까운 측정이 더 상관 높음 | ✅ Trial 1-2가 Trial 1-5보다 상관 높음 |
| **Exchangeable** | 모든 반복 측정 간 상관이 동일 | △ Trial 순서 무시 |
| **Independent** | 상관 없음 | ❌ 반복 측정 특성 무시 |

**이 프로젝트**: **AR(1) 사용** ✅

**면접 답변**:
> "GEE는 반복 측정 데이터를 분석할 때 표준적으로 사용하는 방법입니다.
>
> AR(1) 상관 구조를 선택한 이유는, Trial 1과 2가 Trial 1과 5보다 **시간적으로 가깝고** 따라서 더 높은 상관을 가질 것으로 예상했기 때문입니다.
>
> GEE는 일반 로지스틱 회귀와 달리 **그룹 내 상관을 고려하므로 표준오차가 더 정확**하고, p-value가 과소평가되는 문제를 방지합니다."

#### GEE 주요 결과

| 변수 | 계수 | p-value | 해석 |
|------|------|---------|------|
| **group_numeric** | +0.33 | <0.001 | A그룹이 B그룹보다 Fast 선택 확률 높음 |
| **time_pressure** | +0.94 | <0.001 | 급할수록 Fast 선택 급증 |
| **personality_numeric** | +0.60 | <0.001 | 효율지향일수록 Fast 선택 |
| **trial_index** | -0.40 | <0.001 | Trial 증가 시 Fast 선택 감소 (학습 효과) |
| **congestion_diff** | -0.009 | <0.001 | 혼잡도 차이 클수록 Fast 선택 감소 |

**계수 해석 예시**:
```
trial_index = -0.40

Trial 0 → Trial 4로 증가 시
logit 변화 = -0.40 × 4 = -1.6

확률 변화:
P(Fast | trial=0) = 1/(1+exp(-logit_base)) = 0.75 (예시)
P(Fast | trial=4) = 1/(1+exp(-(logit_base-1.6))) = 0.55

→ 20%p 감소!
```

### 5.3 다중 검정 보정 (Multiple Testing Correction)

#### FDR (False Discovery Rate)

**문제**: 6개 변수를 검정 → Type I error 누적

**해결**: Benjamini-Hochberg FDR 보정

**방법**:
1. p-value를 오름차순 정렬
2. 각 p-value에 대해 FDR = p × (m / rank) 계산
3. FDR < α인 변수만 유의미하다고 결론

**결과**: 6개 변수 모두 FDR < 0.05 ✅

**면접 답변**:
> "여러 변수를 동시에 검정하면 우연히 유의미한 결과가 나올 확률이 증가합니다 (다중 검정 문제).
>
> FDR 보정을 통해 **False Discovery Rate를 5% 이하로 제어**했고, 6개 변수 모두 보정 후에도 유의미하다는 것을 확인했습니다."

---

## 6. 동적 혼잡도 시스템 핵심

### 6.1 왜 동적 혼잡도가 중요한가?

**면접 핵심 답변**:
> "초기 버전에서는 정적 혼잡도(Fast 85%, Relax 45% 고정)를 사용했는데, 문제가 발생했습니다:
>
> **문제**: Fast 선택률이 98% 이상으로 쏠림 → 학습 효과 없음
>
> **원인**: 사용자들이 계속 Fast를 선택해도 혼잡도가 증가하지 않음 → 비현실적
>
> **해결**: 동적 혼잡도 시스템 도입
> - Trial N에서 많이 선택된 경로 → Trial N+1에서 혼잡도 증가
> - 혼잡도 증가 → Fast 선택 확률 감소 (β5=-0.014)
> - **피드백 루프 완성**
>
> **결과**: Fast 92% (T1) → 66% (T5), 목표 70-75% 달성 ✅"

### 6.2 구현 방법 (코드 레벨)

```python
def calculate_dynamic_congestion(trial_number, previous_trial_data):
    """
    Trial별 혼잡도를 동적으로 계산
    """
    if trial_number == 1:
        # 첫 Trial: 기본값
        congestion_fast = 85
        congestion_relax = 45
    else:
        # 이전 Trial 선택 비율 계산
        prev_fast_ratio = (previous_trial_data['selected_route'] == 'Fast').mean()
        prev_relax_ratio = 1 - prev_fast_ratio

        # 선택 비율에 비례하여 혼잡도 증가
        congestion_fast = 85 + (prev_fast_ratio × 120)
        congestion_relax = 45 + (prev_relax_ratio × 120)

        # 범위 제한 (30-200%)
        congestion_fast = np.clip(congestion_fast, 30, 200)
        congestion_relax = np.clip(congestion_relax, 30, 200)

    return congestion_fast, congestion_relax
```

**핵심 파라미터**:
- **BASE_CONGESTION_FAST** = 85%
- **BASE_CONGESTION_RELAX** = 45%
- **CONGESTION_MULTIPLIER** = 120
- **CONGESTION_NOISE_STD** = 8 (개인별 랜덤 변동)

**면접 질문 대비**:
> Q: "120이라는 배수는 어떻게 정했나요?"
>
> A: "시행착오를 통해 결정했습니다.
> - 100: 너무 약함 → Fast 여전히 80% 이상
> - 150: 너무 강함 → Fast 40%대로 급락
> - **120: 적절** → 70-75% 목표 달성
>
> 실무에서는 이런 하이퍼파라미터를 **Grid Search**나 **베이지안 최적화**로 튜닝할 수 있습니다."

### 6.3 Trial별 변화 추이 (암기 필수!)

| Trial | Fast 선택률 | Fast 혼잡도 | Relax 혼잡도 | 설명 |
|-------|------------|------------|-------------|------|
| **1** | 92.16% | 85% (기본) | 45% (기본) | 초기 Fast 쏠림 |
| **2** | 74.82% | **195%** ⬆ | 55% | 혼잡도 폭발, 조정 시작 |
| **3** | 57.13% | 175% | 66% | **큰 조정** (학습) |
| **4** | 66.06% | 154% | 96% | 반등 (균형 모색) |
| **5** | 65.72% | 164% | 86% | **안정화** ✅ |

**평균**: 71.18% (목표 70-75% 달성!)

**면접 스토리텔링**:
> "Trial 1에서 92%의 사용자가 Fast를 선택하자, Trial 2의 Fast 혼잡도가 195%로 급등했습니다.
>
> 사용자들은 이 혼잡도를 경험하고 (β5=-0.014), Trial 3에서 **57%로 급락**했습니다. 이후 시행착오를 거쳐 Trial 5에서 66%로 안정화되었습니다.
>
> 이는 실제 지하철 이용자들이 혼잡한 노선을 피하는 **학습 과정**을 현실적으로 시뮬레이션한 것입니다."

---

## 7. 주요 결과 및 인사이트

### 7.1 A/B Test 주요 결과

#### 1) 그룹 간 차이 (Primary Outcome)

- **A그룹 Fast**: 74.04%
- **B그룹 Fast**: 68.33%
- **차이**: 5.71%p
- **통계적 유의성**: p < 0.001 ✅
- **효과 크기**: Cohen's h = 0.126 (small)

**비즈니스 해석**:
> "UI 디자인만으로 5.71%p의 행동 변화를 유도할 수 있습니다.
>
> 일일 100만 사용자 기준:
> - 57,100명의 경로 선택 변화
> - 만약 Fast 경로 선택 시 광고 노출률이 20% 높다면?
> - 일일 추가 광고 노출: 11,420회
> - 월 추가 수익 (예: CPM $2): $685
>
> **투자 대비 효과**: UI 변경은 개발 비용이 낮으므로 ROI 높음"

#### 2) Trial별 변화 (Learning Effect)

**학습 곡선**:
```
Trial 1: 92.16% ▶
Trial 2: 74.82% ▼
Trial 3: 57.13% ▼▼
Trial 4: 66.06% ▲
Trial 5: 65.72% →
```

**GEE 계수**: trial_index = -0.40 (p<0.001)

**해석**:
> "Trial이 1 증가할 때마다 Fast 선택 확률이 약 10%p 감소합니다.
>
> 이는 사용자들이 혼잡도를 경험하고 학습한다는 증거입니다."

#### 3) Personality 효과

| Personality | Fast 선택률 | 특징 |
|------------|------------|------|
| **efficiency-oriented** | 78.5% | Fast 강한 선호 |
| **neutral** | 70.2% | 중립적 |
| **comfort-oriented** | 61.3% | Relax 선호 |

**GEE 계수**: personality_numeric = +0.60 (p<0.001)

**타겟팅 전략**:
> "Personality type을 파악할 수 있다면:
> - **효율지향 사용자**: Fast 경로 적극 추천
> - **편안함지향 사용자**: Relax 경로 우선 추천
>
> 개인화 추천으로 만족도 향상 가능"

#### 4) 시간 압박 효과

**GEE 계수**: time_pressure = +0.94 (p<0.001) ← **가장 강력한 변수**

| 상황 | Fast 선택률 |
|------|------------|
| 급함 (0) | 85.3% |
| 보통 (1) | 71.2% |
| 여유 (2) | 54.8% |

**실시간 추천 전략**:
> "사용자가 '빨리 가기' 버튼을 누르거나, 출발 시간이 임박했다면 (time_pressure=0):
> - Fast 경로를 상단에 배치
> - '5분 빠릅니다!' 강조
>
> 여유 있는 경우:
> - Relax 경로 추천
> - '쾌적합니다!' 강조"

### 7.2 핵심 인사이트 5가지 (면접 최종 정리)

#### ✅ Insight 1: UI 디자인의 영향력

> "UI 디자인만으로 5.71%p의 행동 변화 유도 가능. 통계적으로 매우 유의미 (p<0.001)"

#### ✅ Insight 2: 학습 효과 존재

> "사용자는 반복 경험을 통해 학습한다. Fast 92% → 66%, -26%p 변화"

#### ✅ Insight 3: 동적 시스템의 중요성

> "정적 모델로는 학습 효과를 포착할 수 없다. 동적 피드백 루프 필수"

#### ✅ Insight 4: 시간 압박이 가장 중요

> "time_pressure가 가장 강력한 예측 변수 (계수 +0.94). 실시간 상황 파악 중요"

#### ✅ Insight 5: 개인화 추천의 가능성

> "Personality type별로 선택률이 17%p 차이. 개인화 추천으로 만족도 향상 가능"

---

## 8. 기술 스택 및 선택 이유

### 8.1 프로그래밍 언어

**Python 3.10+**

**선택 이유**:
1. **데이터 분석 생태계**: Pandas, NumPy, SciPy
2. **통계 분석**: Statsmodels (GEE, Mixed Models)
3. **시각화**: Matplotlib, Seaborn, Plotly
4. **대시보드**: Streamlit (빠른 프로토타이핑)
5. **가독성**: 명확한 문법, 유지보수 용이

**면접 답변**:
> "Python은 데이터 분석 프로젝트의 사실상 표준입니다. 특히 Statsmodels의 GEE 구현이 R의 geepack만큼 강력하며, Streamlit으로 빠르게 대시보드를 구축할 수 있었습니다."

### 8.2 주요 라이브러리

#### 데이터 처리

| 라이브러리 | 버전 | 용도 |
|-----------|------|------|
| **pandas** | 2.3.3 | DataFrame 조작, 집계 |
| **numpy** | 2.3.5 | 수치 계산, 난수 생성 |
| **pyarrow** | 22.0.0 | Parquet 파일 I/O (압축) |

**Parquet 선택 이유**:
> "CSV 대비 Parquet의 장점:
> - **압축률**: 500,000 rows → CSV 50MB, Parquet 10MB (80% 절감)
> - **속도**: 읽기 속도 3-5배 빠름
> - **타입 보존**: int, float, datetime 자동 인식
>
> 대용량 데이터에서는 Parquet이 필수입니다."

#### 통계 분석

| 라이브러리 | 버전 | 용도 |
|-----------|------|------|
| **scipy** | 1.15.2 | 기초 통계 검정 (Z-test, Chi-square) |
| **statsmodels** | 0.14.4 | GEE, Mixed Models, FDR |

**Statsmodels 선택**:
> "Scipy는 기초 검정만 제공하지만, Statsmodels는 반복 측정 데이터를 위한 GEE, Mixed Models를 지원합니다.
>
> `GEE(..., cov_struct=Autoregressive())`로 AR(1) 상관 구조를 손쉽게 적용할 수 있습니다."

#### 시각화

| 라이브러리 | 버전 | 용도 |
|-----------|------|------|
| **matplotlib** | 3.10.1 | 기본 플롯, 세밀한 커스터마이징 |
| **seaborn** | 0.13.2 | 통계 차트 (barplot, boxplot) |
| **plotly** | 6.5.0 | 인터랙티브 차트 (대시보드) |

**3개 라이브러리 사용 이유**:
> "각각 장단점이 있습니다:
> - **Matplotlib**: 세밀한 제어 (DPI, 폰트, 레이아웃), 논문급 품질
> - **Seaborn**: 95% CI 자동 계산, 통계 차트 특화
> - **Plotly**: 마우스 hover, zoom 등 인터랙티브
>
> 정적 이미지(PNG)는 Matplotlib+Seaborn, 대시보드는 Plotly로 분리했습니다."

#### 대시보드

| 라이브러리 | 버전 | 용도 |
|-----------|------|------|
| **streamlit** | 1.52.0 | 웹 대시보드 프레임워크 |

**Streamlit vs Dash vs Flask**:

| 프레임워크 | 장점 | 단점 | 선택 이유 |
|----------|------|------|----------|
| **Streamlit** | 초고속 개발, Python만 | 커스터마이징 제한 | ✅ 빠른 프로토타입 |
| Dash | Plotly 통합, 상세 제어 | 코드 복잡 | - |
| Flask | 완전한 제어 | HTML/CSS/JS 필요 | - |

**면접 답변**:
> "Streamlit을 선택한 이유는 **개발 속도** 때문입니다.
>
> 6일 프로젝트에서 Flask로 HTML/CSS를 작성할 시간이 없었고, Streamlit은 순수 Python만으로 1일 만에 대시보드를 완성할 수 있었습니다.
>
> 실무에서도 **PoC(Proof of Concept)**나 **내부 대시보드**는 Streamlit, **고객용 프로덕션**은 React+Flask를 사용하는 것이 일반적입니다."

### 8.3 프로젝트 구조 (Architecture)

```
지하철ABTEST/
│
├── config.py                     # 중앙 설정 파일 ⭐
│   └── 모든 파라미터 (NUM_USERS, BETA 계수 등)
│
├── data/                         # 데이터 생성 모듈
│   ├── generate_complete_data.py # 통합 생성 스크립트 (동적)
│   └── synthetic_data_dynamic.parquet  # 최종 데이터
│
├── analysis/                     # 통계 분석 모듈
│   ├── basic_tests.py            # Z-test, Chi-square
│   ├── mixed_models.py           # GEE 분석
│   └── visualization.py          # 차트 생성
│
├── figures/                      # 시각화 산출물
│   └── 01-08_*.png               # 8개 차트 (300 DPI)
│
└── app.py                        # Streamlit 대시보드
```

**config.py 중앙 관리의 장점**:
> "모든 파라미터를 config.py에 모아서:
> 1. **일관성**: 모든 스크립트가 동일한 파라미터 사용
> 2. **재현성**: RANDOM_SEED 한 곳에서 관리
> 3. **유지보수**: 파라미터 변경 시 config.py만 수정
>
> 실무에서는 이를 더 발전시켜 YAML 파일이나 환경변수로 관리합니다."

---

## 9. 도전 과제 및 해결 방법

### 도전 1: Fast 쏠림 현상 (98%)

**문제**:
> "초기 버전에서 Fast 선택률이 98% 이상으로 쏠려서, A/B Test가 무의미했습니다."

**원인 분석**:
1. β0_A = 0.3 (A그룹 Fast 선호) ✅
2. time_pressure 대부분 급함 → β1 = 1.2 효과 ✅
3. Fast가 11분 빠름 → β3 = 0.18 효과 ✅
4. **문제**: 혼잡도가 고정 → Fast를 선택해도 불이익 없음

**해결 과정**:
```
시도 1: β 계수 감소
→ 여전히 95% 이상

시도 2: 혼잡도 차이 증가 (Fast 150%, Relax 45%)
→ 90% 수준

시도 3: 동적 혼잡도 시스템 도입 ⭐
→ 목표 달성! 71.18%
```

**핵심 해결책**:
> "**피드백 루프**를 구현했습니다. Trial N에서 많이 선택된 경로는 Trial N+1에서 혼잡도가 증가하고, β5=-0.014 효과로 선택 확률이 감소합니다."

**교훈**:
> "정적 시뮬레이션은 현실을 반영하지 못합니다. 실제 시스템은 대부분 **동적**이며, 사용자 행동이 시스템 상태에 영향을 주고, 시스템 상태가 다시 사용자 행동에 영향을 줍니다."

### 도전 2: 데이터 생성 순서 문제

**문제**:
> "처음에는 모든 Trial을 한 번에 생성했는데, previous_choice와 congestion_experience가 제대로 반영되지 않았습니다."

**오류 코드** (잘못된 접근):
```python
# ❌ 잘못된 방법: 모든 trial을 한 번에 생성
for trial_num in range(1, 6):
    trial_data = generate_trial_base_data(df_users, trial_num)
    # 이 시점에 previous_trial이 없음!
```

**해결**:
```python
# ✅ 올바른 방법: 순차 처리
all_trials = []
previous_trial = None

for trial_num in range(1, 6):
    # 1. 기본 데이터 생성
    trial_data = generate_trial_base_data(df_users, trial_num)

    # 2. 동적 혼잡도 계산 (previous_trial 사용)
    congestion_fast, congestion_relax = calculate_dynamic_congestion(
        trial_num, previous_trial
    )

    # 3. 혼잡도 추가
    trial_data = add_congestion_to_trial(trial_data, congestion_fast, congestion_relax)

    # 4. 선택 생성 (previous_trial 사용)
    trial_data['selected_route'] = generate_route_choice(trial_data, previous_trial)

    # 5. 다음 trial을 위해 저장
    previous_trial = trial_data
    all_trials.append(trial_data)
```

**교훈**:
> "데이터 생성 순서가 결과에 결정적 영향을 줍니다. 특히 **시계열 데이터**나 **피드백 시스템**에서는 반드시 순차 처리해야 합니다."

### 도전 3: 경고 메시지 200+ 개

**문제**:
> "시각화 스크립트 실행 시 UserWarning, FutureWarning이 200개 이상 출력되어 가독성이 떨어졌습니다."

**원인**:
1. `tight_layout()` 중복 호출
2. `.iloc` 대신 인덱싱
3. Deprecated 함수 사용

**해결**:
```python
# 1. Warnings 필터
import warnings
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

# 2. tight_layout() 중복 제거
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
# ... 차트 작성 ...
plt.tight_layout()  # ✅ 한 번만 호출
plt.savefig(...)

# 3. .iloc[] 사용
result.params.iloc[idx]  # ✅ .iloc 명시
```

**결과**: 경고 200+ → 0개

### 도전 4: 한글 폰트 문제

**문제**:
> "matplotlib에서 한글이 깨져서 □□□로 표시되었습니다."

**해결**:
```python
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# 사용 가능한 한글 폰트 자동 탐지
def get_korean_font():
    fonts = fm.findSystemFonts(fontpaths=None, fontext='ttf')
    korean_fonts = ['Malgun Gothic', 'NanumGothic', 'AppleGothic']

    for korean_font in korean_fonts:
        for font_path in fonts:
            if korean_font.lower() in font_path.lower():
                return fm.FontProperties(fname=font_path).get_name()
    return 'DejaVu Sans'  # 폴백

korean_font = get_korean_font()
plt.rcParams['font.family'] = korean_font
plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지
```

**교훈**:
> "운영체제별로 한글 폰트가 다르므로, 하드코딩 대신 **자동 탐지**가 안전합니다."

### 도전 5: 대용량 데이터 처리

**문제**:
> "500,000 rows 데이터를 Streamlit에서 로드할 때 느렸습니다."

**해결**:
```python
@st.cache_data  # ⭐ 캐싱
def load_data():
    df = pd.read_parquet('data/synthetic_data_dynamic.parquet')
    return df

# 첫 로드: 2초
# 이후 로드: 0.01초 (캐시 사용)
```

**성능 최적화**:
1. **Parquet 사용**: CSV 대비 5배 빠름
2. **@st.cache_data**: 반복 로드 방지
3. **샘플링**: 산점도는 5,000개만 표시

---

## 10. 예상 면접 질문 60개 + 모범 답변

### 카테고리 A: 프로젝트 개요 (10문)

#### Q1. 이 프로젝트를 한 줄로 설명하면?

**A**: "지하철 앱 UI 디자인이 사용자 경로 선택에 미치는 영향을 분석한 A/B Test 시뮬레이션 프로젝트로, 10만 명 5회 반복 데이터와 동적 혼잡도 피드백 시스템을 구현했습니다."

#### Q2. 왜 이 주제를 선택했나요?

**A**: "실무 A/B 테스트에서 반복 측정 데이터를 다루는 경험을 쌓고 싶었고, 특히 **동적 시스템**(사용자 행동이 시스템에 영향 → 시스템이 다시 행동에 영향)을 시뮬레이션하는 것이 도전적이고 흥미로웠습니다."

#### Q3. 실제 데이터가 아닌 합성 데이터를 사용한 이유는?

**A**: "실제 지하철 데이터는 개인정보 보호 문제와 데이터 접근성 문제가 있습니다. 합성 데이터를 사용하면:
1. **완전한 통제**: 원하는 효과 크기, 분포를 설계 가능
2. **재현성**: random seed로 누구나 동일 결과 재현
3. **Ground Truth**: 실제 계수를 알고 있어 분석 검증 가능
4. **윤리 문제 없음**: 개인정보 보호법 위반 없음"

#### Q4. 가장 어려웠던 부분은?

**A**: "**동적 혼잡도 피드백 시스템** 구현입니다. 초기에는 Fast 선택률이 98%로 쏠려서, 파라미터를 조정해도 해결되지 않았습니다.
Trial N의 결과가 Trial N+1에 영향을 주는 **순차 처리 구조**로 변경하고, CONGESTION_MULTIPLIER=120으로 튜닝하여 목표(70-75%)를 달성했습니다."

#### Q5. 이 프로젝트의 핵심 성과 3가지는?

**A**:
1. **통계적 유의성**: A그룹이 B그룹보다 5.71%p 높음 (p<0.001)
2. **학습 효과 입증**: Trial 1 (92%) → Trial 5 (66%), -26%p 변화
3. **완전한 파이프라인**: 데이터 생성 → 분석 → 시각화 → 대시보드까지 end-to-end 구현

#### Q6. 프로젝트 기간과 규모는?

**A**: "6일간 집중 개발했고, 3,000+ 코드 라인, 8개 시각화, 1개 대시보드를 완성했습니다. 10만 명 × 5 trials = 50만 rows 데이터를 생성하고 분석했습니다."

#### Q7. 이 프로젝트로 배운 가장 중요한 것은?

**A**: "**동적 시스템 설계의 중요성**입니다. 정적 모델로는 현실의 피드백 루프를 포착할 수 없고, 반복 측정 데이터를 제대로 분석하려면 GEE 같은 특화된 방법이 필요하다는 것을 배웠습니다."

#### Q8. 실무에 어떻게 적용할 수 있나요?

**A**: "모바일 앱/웹 서비스의 A/B 테스트 설계와 분석에 직접 적용 가능합니다. 특히:
- 반복 사용자 행동 분석 (일별, 주별 패턴)
- 동적 추천 시스템 효과 측정
- 시간에 따른 전환율 변화 추적"

#### Q9. 이 프로젝트의 한계는?

**A**: "합성 데이터이므로 실제 사용자의 **예측 불가능한 행동**(예: 앱 오류, 외부 이벤트)이 반영되지 않았습니다. 또한 로지스틱 회귀는 **선형 가정**을 하므로, 복잡한 비선형 관계는 포착하지 못했습니다. 실무에서는 XGBoost 같은 비선형 모델도 함께 사용할 수 있습니다."

#### Q10. 다시 한다면 어떻게 개선하겠나요?

**A**: "3가지 개선:
1. **머신러닝 예측 모델**: 사용자 선택 예측 (Random Forest, XGBoost)
2. **실시간 시뮬레이션**: Streamlit에서 파라미터 조정 후 즉시 재실행
3. **A/B/C Test**: 3개 이상 그룹 비교"

---

### 카테고리 B: A/B 테스트 설계 (10문)

#### Q11. A그룹과 B그룹의 차이는 정확히 무엇인가요?

**A**: "로지스틱 회귀의 절편(β0)이 다릅니다:
- A그룹: β0 = +0.3 (Fast 경로 중심 UI)
- B그룹: β0 = -0.2 (Relax 경로 중심 UI)
이는 UI 디자인에서 '빠른 도착' vs '편안한 이동' 중 무엇을 강조하는지를 시뮬레이션한 것입니다."

#### Q12. 10만 명으로 충분한가요?

**A**: "Cohen's h = 0.2 (small effect)를 80% 검정력으로 감지하려면 최소 3,000명이 필요합니다. 10만 명은 충분하며, 하위 그룹 분석(Personality별, Trial별)을 위한 여유도 있습니다."

#### Q13. 왜 5회 반복인가요?

**A**: "학습 효과를 관찰하기 위한 최소 횟수입니다. 너무 적으면(2-3회) 패턴을 보기 어렵고, 너무 많으면(10회+) 현실성이 떨어집니다. 실제로 5회면 초기 쏠림 → 조정 → 안정화 과정을 관찰할 수 있었습니다."

#### Q14. 랜덤 할당은 어떻게 했나요?

**A**: "`np.random.choice(['A', 'B'], p=[0.5, 0.5])`로 완전 랜덤 할당했고, 결과적으로 A그룹 50,000명, B그룹 50,000명으로 완벽히 균형 잡혔습니다."

#### Q15. 재현성(Reproducibility)은 어떻게 보장했나요?

**A**: "모든 스크립트 시작 시 `np.random.seed(42)`를 설정하여, 누구나 동일한 결과를 재현할 수 있습니다. config.py에서 RANDOM_SEED를 중앙 관리합니다."

#### Q16. 목표 지표(Primary Metric)는 무엇인가요?

**A**: "**Fast 경로 선택률**입니다. A그룹과 B그룹의 Fast 선택률 차이가 통계적으로 유의미한지 검정하는 것이 주 목표입니다."

#### Q17. 샘플 크기를 사전에 계산했나요?

**A**: "네, 검정력 분석(Power Analysis)를 통해 Cohen's h = 0.2, power = 0.8, α = 0.05 기준으로 최소 3,000명이 필요함을 확인했습니다. 10만 명은 하위 그룹 분석을 고려한 충분한 샘플입니다."

#### Q18. 교란 변수(Confounding)는 어떻게 처리했나요?

**A**: "랜덤 할당으로 교란 변수를 균등하게 분배했고, GEE 분석에서 time_pressure, personality 등을 공변량(covariate)으로 포함하여 통제했습니다."

#### Q19. 실험군/대조군의 정의는?

**A**: "A그룹을 실험군(빠른 경로 강조 UI), B그룹을 대조군(여유 경로 강조 UI)으로 정의했습니다. 하지만 두 그룹 모두 '처치'를 받으므로, 엄밀히는 **두 가지 UI 디자인 비교**입니다."

#### Q20. 윤리적 고려사항은?

**A**: "합성 데이터이므로 개인정보 보호 문제가 없습니다. 실제 실험이라면 IRB 승인, 사용자 동의, A/B Test 기간 제한 등을 고려해야 합니다."

---

### 카테고리 C: 데이터 생성 (10문)

#### Q21. 로지스틱 회귀 모델을 설명해주세요.

**A**: "Fast 선택 확률을 결정하는 모델입니다:
```
logit = β0 + β1×time_pressure + β2×personality + ... + ε
P(Fast) = 1 / (1 + exp(-logit))
```
7개 변수(그룹, 시간압박, 성격, 시간차이, 이전선택, 혼잡도, 노이즈)가 Fast 선택에 영향을 줍니다."

#### Q22. β4 (previous_choice)가 음수인 이유는?

**A**: "**학습 효과**를 나타냅니다. 이전 trial에서 Fast를 선택한 사용자(+1)는 혼잡도를 경험했으므로, 다음 trial에서 Fast 선택 확률이 **감소**합니다. β4=-0.7은 이 부정적 피드백을 모델링한 것입니다."

#### Q23. β5 (congestion)도 음수인데, 의미는?

**A**: "이전 trial에서 경험한 혼잡도가 높을수록 Fast 선택 확률이 **감소**합니다. β5=-0.014는 혼잡도 1% 증가당 logit이 0.014 감소, 즉 약 10% 혼잡도 증가 시 선택 확률이 약 3%p 감소하는 효과입니다."

#### Q24. Personality type 비율을 왜 그렇게 설정했나요?

**A**: "효율지향 55%, 편안함지향 35%, 중립 10%로 설정했는데, 이는 일반적으로 **효율을 중시하는 사람이 더 많다**는 가정입니다. 실제 설문조사 데이터가 있다면 그에 맞춰 조정할 수 있습니다."

#### Q25. Time pressure 분포는?

**A**: "사용자별 baseline은 N(μ=1, σ=0.5)이고, trial별로 N(0, 0.3) 노이즈를 더한 후 0, 1, 2로 반올림합니다. 결과적으로 대부분 '보통(1)'이고, 급함(0)과 여유(2)가 적절히 섞입니다."

#### Q26. 경로 시간은 어떻게 생성했나요?

**A**: "Fast는 N(25, 2), Relax는 N(36, 3)의 정규분포에서 샘플링하고, 최소값 제한(Fast ≥ 10분, Relax ≥ 15분)을 적용했습니다. 평균 11분 차이가 있습니다."

#### Q27. 혼잡도 노이즈를 추가한 이유는?

**A**: "개인별 경험 차이를 반영하기 위해서입니다. 같은 시간대라도 어떤 칸에 타는지, 환승역이 어디인지에 따라 혼잡도가 다를 수 있습니다. N(평균, 8)의 노이즈로 이를 시뮬레이션했습니다."

#### Q28. 만족도는 어떻게 생성했나요?

**A**: "기본 3점 + 매칭 보너스(성격-선택 일치 시 +2) + 압박 패널티(급한데 Relax 선택 시 -1) + 혼잡도 패널티(임계값 초과 시 비례 감소) + 노이즈로 계산하고, 0-5점으로 제한했습니다."

#### Q29. 의사결정 시간은 왜 생성했나요?

**A**: "실무에서 UI 디자인이 **결정 속도**에 미치는 영향도 중요하기 때문입니다. 급할수록 빨리 결정하도록 time_pressure 효과를 반영했습니다. 하지만 주 분석에는 사용하지 않았고, 추가 분석 가능성을 위해 생성했습니다."

#### Q30. 데이터 생성에 걸린 시간은?

**A**: "10만 명 × 5 trials = 50만 rows 생성에 약 2-3분 소요됩니다. 순차 처리가 필요하므로 병렬화가 어렵지만, 개인 PC에서 충분히 처리 가능한 규모입니다."

---

### 카테고리 D: 동적 혼잡도 시스템 (10문)

#### Q31. 동적 혼잡도란 무엇인가요?

**A**: "Trial N에서 많이 선택된 경로일수록 Trial N+1에서 혼잡도가 높아지는 시스템입니다. 현실의 '러시아워에 인기 노선이 혼잡해진다'를 시뮬레이션한 것입니다."

#### Q32. 정적 혼잡도 vs 동적 혼잡도, 차이는?

**A**:
- **정적**: Fast 85%, Relax 45% 고정 → Fast 98% 선택 (비현실적)
- **동적**: Trial별로 변동 → Fast 92% → 66% (현실적 학습 효과)

#### Q33. CONGESTION_MULTIPLIER=120은 어떻게 정했나요?

**A**: "시행착오로 결정했습니다. 100은 너무 약하고, 150은 너무 강해서, 120에서 목표(70-75%)를 달성했습니다. 실무에서는 Grid Search나 베이지안 최적화로 자동화할 수 있습니다."

#### Q34. Trial 1에서 Fast가 92%인 이유는?

**A**: "혼잡도가 기본값(Fast 85%, Relax 45%)이고, Fast가 11분 빠르며, 대부분 사용자가 효율지향이므로 Fast를 압도적으로 선택합니다. 이는 **정보가 없을 때의 초기 선택**을 나타냅니다."

#### Q35. Trial 3에서 57%로 급락한 이유는?

**A**: "Trial 2에서 Fast 혼잡도가 195%로 폭발하여, 사용자들이 이를 경험하고 (β5=-0.014) + 이전 Fast 선택 경험 (β4=-0.7) 효과로 **과잉 반응**했기 때문입니다. Trial 4에서 66%로 반등하며 균형을 찾아갑니다."

#### Q36. 왜 Trial 5에서 안정화되나요?

**A**: "사용자들이 시행착오를 거쳐 **최적 선택 비율**을 학습했기 때문입니다. 66%가 선택하면 혼잡도가 적정 수준으로 유지되어, 더 이상 큰 변동이 없습니다. 이는 **내쉬 균형(Nash Equilibrium)** 개념과 유사합니다."

#### Q37. 혼잡도-시간 지연 계수(0.08)는?

**A**: "혼잡도 1% 증가당 0.08분(약 5초) 지연을 의미합니다. 예: 혼잡도 195%면 기본 25분 + (195-85)×0.08 = 33.8분이 됩니다. 이는 대략적인 현실 추정입니다."

#### Q38. 동적 시스템의 장점은?

**A**: "현실의 **피드백 루프**를 반영하여 더 정확한 시뮬레이션이 가능합니다. 정적 모델로는 불가능한 **학습 효과, 균형점 탐색, 시간 변화**를 포착할 수 있습니다."

#### Q39. 단점이나 한계는?

**A**: "순차 처리가 필요하므로 **병렬화가 어렵고**, 하이퍼파라미터(CONGESTION_MULTIPLIER) 튜닝이 필요합니다. 또한 초기 조건에 민감할 수 있습니다."

#### Q40. 실무에서 동적 시스템 예시는?

**A**:
1. **추천 알고리즘**: 추천 → 클릭 → 다음 추천에 반영
2. **가격 정책**: 수요 증가 → 가격 상승 → 수요 감소
3. **트래픽 관리**: 혼잡 → 우회 유도 → 혼잡 완화

---

### 카테고리 E: 통계 분석 (10문)

#### Q41. GEE가 무엇이고 왜 사용했나요?

**A**: "Generalized Estimating Equations로, 반복 측정 데이터의 **그룹 내 상관**을 고려하는 방법입니다. 각 사용자가 5번 측정되므로 독립성 가정이 위배되는데, GEE는 이를 AR(1) 상관 구조로 모델링합니다."

#### Q42. AR(1) vs Exchangeable, 어떤 차이인가요?

**A**:
- **AR(1)**: 시간적으로 가까운 측정이 더 상관 높음 (Trial 1-2 > Trial 1-5)
- **Exchangeable**: 모든 반복 측정 간 상관 동일
이 프로젝트는 시간 순서가 중요하므로 AR(1)을 선택했습니다."

#### Q43. p-value < 0.001의 의미는?

**A**: "귀무가설(H0: 그룹 간 차이 없음)이 참일 때, 관측된 결과(또는 더 극단적인 결과)가 나올 확률이 0.1% 미만이라는 뜻입니다. 즉, **우연히 이런 차이가 나올 가능성이 거의 없다**는 의미입니다."

#### Q44. Cohen's h = 0.126이 small effect인데, 문제 아닌가요?

**A**: "아닙니다. 표본 크기가 매우 크면 (10만 명) 작은 효과도 감지할 수 있습니다. **통계적 유의성**과 **실질적 중요성**은 다릅니다. 5.71%p 차이는 일일 100만 사용자 기준 57,100명의 행동 변화이므로 **비즈니스적으로 충분히 의미있습니다**."

#### Q45. FDR 보정이 필요한 이유는?

**A**: "여러 변수를 동시에 검정하면 **우연히 유의미한 결과**가 나올 확률이 증가합니다 (다중 검정 문제). FDR 보정으로 False Discovery Rate를 5% 이하로 제어하여, 진짜 효과만 찾아냅니다."

#### Q46. Mixed Model vs GEE, 차이는?

**A**:
- **Mixed Model**: 개체별 랜덤 효과 추정, 예측에 유용
- **GEE**: 모집단 평균 효과 추정, 추론에 유용
이 프로젝트는 **모집단 평균 비교**가 목적이므로 GEE가 적합합니다."

#### Q47. 95% 신뢰구간의 의미는?

**A**: "같은 실험을 100번 반복하면, 그 중 95번은 실제 모수(true parameter)가 이 구간 안에 들어간다는 뜻입니다. A그룹 Fast 선택률의 95% CI가 [0.736, 0.745]라면, 실제 비율이 이 범위 안에 있을 확률이 95%입니다."

#### Q48. Type I error vs Type II error?

**A**:
- **Type I error (α)**: 실제 차이가 없는데 있다고 결론 (False Positive) → α=0.05로 제어
- **Type II error (β)**: 실제 차이가 있는데 없다고 결론 (False Negative) → Power=1-β=0.8 목표"

#### Q49. 통계적 유의성만으로 의사결정할 수 있나요?

**A**: "아닙니다. **효과 크기, 신뢰구간, 비즈니스 맥락**을 함께 고려해야 합니다. p<0.001이어도 효과 크기가 너무 작으면 (예: 0.01%p 차이) 실무적으로 무의미할 수 있습니다."

#### Q50. 이 프로젝트에서 사용한 모든 통계 검정은?

**A**:
1. Two-Proportion Z-Test (그룹 간 비율 비교)
2. Chi-square Test (독립성 검정)
3. Cohen's h (효과 크기)
4. GEE AR(1) (반복 측정 분석)
5. FDR Correction (다중 검정 보정)

---

### 카테고리 F: 시각화 및 대시보드 (10문)

#### Q51. 8개 차트가 무엇인가요?

**A**:
1. A vs B 비교 (Bar + 95% CI)
2. Personality 분석
3. Trial 추이
4. 급함 × Personality 히트맵
5. GEE 계수 플롯
6. 만족도 분포
7. 혼잡도 동적 변화
8. 학습 효과

#### Q52. Matplotlib vs Seaborn vs Plotly, 차이는?

**A**:
- **Matplotlib**: 세밀한 제어, 논문급 품질, 정적 이미지
- **Seaborn**: 통계 차트 특화, 95% CI 자동, Matplotlib 기반
- **Plotly**: 인터랙티브, 마우스 hover, zoom, 대시보드용

#### Q53. 95% CI를 차트에 포함한 이유는?

**A**: "불확실성을 시각화하기 위해서입니다. 단순히 점 추정치만 표시하면, A그룹 74%, B그룹 68%가 얼마나 **확실한지** 알 수 없습니다. CI를 보면 두 구간이 **겹치지 않으므로** 차이가 명확함을 직관적으로 알 수 있습니다."

#### Q54. 300 DPI로 저장한 이유는?

**A**: "출판/발표 품질을 위해서입니다. 화면용은 72-96 DPI면 충분하지만, 인쇄나 확대 시 깨지지 않으려면 300 DPI가 표준입니다. 대신 파일 크기는 커집니다 (약 500KB per chart)."

#### Q55. Streamlit을 선택한 이유는?

**A**: "**빠른 프로토타입** 때문입니다. Flask는 HTML/CSS/JS가 필요하고, Dash는 코드가 복잡합니다. Streamlit은 순수 Python만으로 1일 만에 대시보드를 완성할 수 있었습니다."

#### Q56. 대시보드의 5개 페이지는?

**A**:
1. 📊 프로젝트 개요 (요약 지표)
2. 📈 시각화 갤러리 (8개 PNG)
3. 📋 통계 분석 (GEE, FDR 테이블)
4. 🔍 데이터 탐색 (필터링, 테이블)
5. 🎯 비교분석 (Plotly 인터랙티브)

#### Q57. @st.cache_data의 역할은?

**A**: "데이터 로드를 한 번만 수행하고 캐시에 저장하여, 페이지 전환 시 매번 다시 로드하지 않도록 합니다. 500,000 rows 데이터를 읽는 데 2초 걸리지만, 캐시 사용 시 0.01초로 단축됩니다."

#### Q58. 인터랙티브 차트의 장점은?

**A**: "사용자가 **직접 탐색**할 수 있습니다. 예: 마우스 hover로 정확한 값 확인, zoom으로 특정 구간 확대, 필터로 원하는 그룹만 표시. 정적 이미지로는 불가능한 **탐색적 분석**이 가능합니다."

#### Q59. 한글 폰트 문제는 어떻게 해결했나요?

**A**: "시스템에서 사용 가능한 한글 폰트를 자동 탐지하여 설정했습니다:
```python
korean_fonts = ['Malgun Gothic', 'NanumGothic', 'AppleGothic']
# 첫 번째로 발견된 폰트 사용
```
하드코딩하면 OS마다 다른 폰트로 에러가 나므로, 자동 탐지가 안전합니다."

#### Q60. 시각화에서 가장 신경 쓴 부분은?

**A**: "**색상 접근성**과 **가독성**입니다. A그룹은 파란색, B그룹은 보라색으로 일관되게 사용하여 직관적이도록 했고, 글자 크기는 최소 10pt 이상으로 설정하여 가독성을 확보했습니다."

---

## 11. 수치로 말하기 (정량적 성과)

### 면접에서 바로 답변할 수 있도록 암기하세요!

#### 프로젝트 규모

- **참가자**: 100,000명 (A: 50,000, B: 50,000)
- **데이터**: 500,000 rows (5 trials × 100,000)
- **변수**: 25개 컬럼
- **코드**: 3,000+ lines
- **개발 기간**: 6일
- **파일 크기**: Parquet 10MB (CSV 대비 80% 절감)

#### 주요 결과

- **Fast 선택률**: 71.18% (목표 70-75% ✅)
- **A그룹 Fast**: 74.04%
- **B그룹 Fast**: 68.33%
- **차이**: 5.71%p
- **p-value**: < 0.001
- **Cohen's h**: 0.126 (small effect)
- **학습 효과**: Trial 1 (92.16%) → Trial 5 (65.72%), -26.44%p

#### 통계 검정

- **Z-통계량**: 62.3
- **χ²**: 3881.5
- **GEE 계수 (주요)**:
  - group_numeric: +0.33 (p<0.001)
  - trial_index: -0.40 (p<0.001)
  - time_pressure: +0.94 (p<0.001)
- **FDR**: 6개 변수 모두 < 0.05

#### 시각화

- **차트**: 8개 (300 DPI)
- **대시보드 페이지**: 5개
- **인터랙티브 차트**: Plotly 4종

#### 성능

- **데이터 생성 시간**: 2-3분
- **통계 분석 시간**: 5-10분
- **대시보드 로드 시간**: 2초 (첫 로드), 0.01초 (캐시)

---

## 12. 코드 품질 및 Best Practices

### 12.1 재현성 (Reproducibility)

```python
# 모든 스크립트 시작 부분
import numpy as np
import config

np.random.seed(config.RANDOM_SEED)  # 42
```

**면접 답변**:
> "누구나 동일한 결과를 재현할 수 있도록 random seed를 고정했습니다. 이는 과학적 연구와 디버깅에 필수적입니다."

### 12.2 중앙 집중식 설정 관리

```python
# config.py
NUM_USERS = 100000
NUM_TRIALS = 5
RANDOM_SEED = 42
BETA_0_A = 0.3
# ... 모든 파라미터
```

**장점**:
- 일관성 보장
- 변경 용이 (한 곳만 수정)
- 버전 관리 편리

### 12.3 모듈화 (Modularity)

```python
# 함수별 명확한 책임
def generate_trial_base_data(df_users, trial_number):
    """Trial 기본 데이터 생성"""
    pass

def calculate_dynamic_congestion(trial_number, previous_trial):
    """동적 혼잡도 계산"""
    pass

def generate_route_choice(trial_data, previous_trial):
    """경로 선택 생성"""
    pass
```

**면접 답변**:
> "각 함수는 **단일 책임 원칙(SRP)**을 따르며, 재사용과 테스트가 용이합니다."

### 12.4 Docstring 및 주석

```python
def calculate_dynamic_congestion(trial_number, previous_trial_data=None):
    """
    동적 혼잡도 계산: 이전 trial 선택 비율에 따라 결정

    Args:
        trial_number: 현재 trial 번호
        previous_trial_data: 이전 trial DataFrame (selected_route 포함)

    Returns:
        tuple: (congestion_fast, congestion_relax) - 각각 scalar 값
    """
```

**면접 답변**:
> "모든 함수에 docstring을 작성하여 코드 가독성과 유지보수성을 높였습니다."

### 12.5 에러 처리

```python
def load_data(file_path):
    try:
        df = pd.read_parquet(file_path)
    except FileNotFoundError:
        raise FileNotFoundError(f"데이터 파일을 찾을 수 없습니다: {file_path}")

    if len(df) == 0:
        raise ValueError(f"빈 데이터 파일입니다: {file_path}")

    return df
```

**면접 답변**:
> "명확한 에러 메시지로 디버깅을 용이하게 하고, 빈 파일 등의 엣지 케이스를 처리했습니다."

### 12.6 성능 최적화

1. **Parquet 사용**: CSV 대비 80% 압축, 5배 빠른 읽기
2. **Vectorization**: Pandas vectorized 연산 (for loop 대신)
3. **Caching**: Streamlit @st.cache_data

**면접 답변**:
> "Parquet는 컬럼 기반 저장으로 압축률이 높고, Pandas는 내부적으로 NumPy를 사용하여 C 수준의 속도를 제공합니다. 50만 rows를 처리하는데도 2-3분이면 충분합니다."

---

## 13. 향후 개선 방안

### 1. 머신러닝 예측 모델

**현재**: 로지스틱 회귀로 **확률 생성**
**개선**: Random Forest, XGBoost로 **선택 예측**

**기대 효과**:
- 비선형 관계 포착
- 변수 중요도 자동 계산
- 예측 정확도 향상

**구현 예시**:
```python
from sklearn.ensemble import RandomForestClassifier

X = df[['group', 'time_pressure', 'personality', ...]]
y = (df['selected_route'] == 'Fast').astype(int)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X, y)

# Feature Importance
importances = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)
```

### 2. 실시간 시뮬레이션

**현재**: 파라미터 변경 시 스크립트 재실행
**개선**: Streamlit에서 슬라이더로 파라미터 조정 → 즉시 재계산

**구현 예시**:
```python
# Streamlit sidebar
beta_0_a = st.slider('A그룹 절편 (β0)', -1.0, 1.0, 0.3, 0.1)
congestion_mult = st.slider('혼잡도 배수', 50, 200, 120, 10)

# 버튼 클릭 시 재생성
if st.button('시뮬레이션 실행'):
    with st.spinner('생성 중...'):
        df = generate_data(beta_0_a, congestion_mult)
        st.success('완료!')
```

### 3. A/B/C 테스트

**현재**: 2개 그룹 (A, B)
**개선**: 3개 이상 그룹 지원 (A, B, C, ...)

**예시**:
- A: Fast 중심 UI
- B: Relax 중심 UI
- C: 혼잡도 실시간 표시 UI ← **새로운 아이디어**

**통계 분석**: ANOVA, Tukey HSD (사후 검정)

### 4. 생존 분석 (Survival Analysis)

**질문**: "사용자가 앱을 며칠 동안 사용하는가?"

**방법**: Kaplan-Meier curve, Cox regression

**구현**:
```python
from lifelines import KaplanMeierFitter

kmf = KaplanMeierFitter()
kmf.fit(durations=df['days_active'], event_observed=df['churned'])
kmf.plot()
```

### 5. 베이지안 A/B Test

**현재**: 빈도주의 통계 (Frequentist)
**개선**: 베이지안 접근 (Bayesian)

**장점**:
- "A가 B보다 나을 확률"을 직접 계산
- 조기 중단 결정 용이
- 사전 지식 활용

**라이브러리**: PyMC3, Stan

### 6. 인과 추론 (Causal Inference)

**질문**: "UI 변경이 **정말** 선택을 **변화시켰는가?**" (상관 vs 인과)

**방법**:
- Propensity Score Matching
- Difference-in-Differences
- Instrumental Variables

**라이브러리**: DoWhy, CausalML

### 7. 강화학습 (Reinforcement Learning)

**질문**: "사용자 행동을 보고 **최적 추천**을 실시간으로 학습"

**방법**: Multi-Armed Bandit (Thompson Sampling, UCB)

**응용**: 동적 UI 조정 (A/B 비율을 시간에 따라 조정)

---

## 최종 면접 준비 체크리스트

### ✅ 암기해야 할 핵심 수치

- [ ] 참가자: 10만 명 (A: 5만, B: 5만)
- [ ] 데이터: 50만 rows
- [ ] Fast 선택률: 71.18%
- [ ] A-B 차이: 5.71%p
- [ ] p-value: < 0.001
- [ ] Cohen's h: 0.126
- [ ] 학습 효과: -26.44%p (Trial 1 → 5)
- [ ] Trial별: 92% → 75% → 57% → 66% → 66%

### ✅ 설명할 수 있어야 할 개념

- [ ] 로지스틱 회귀 모델 (7개 계수 의미)
- [ ] 동적 혼잡도 공식
- [ ] GEE와 AR(1) 상관 구조
- [ ] FDR 보정
- [ ] Cohen's h 해석
- [ ] 학습 효과 (β4, β5)
- [ ] Two-Proportion Z-Test
- [ ] 효과 크기 vs 통계적 유의성

### ✅ 답변 준비해야 할 질문

- [ ] 30초 엘리베이터 피치
- [ ] 왜 이 프로젝트를 했나?
- [ ] 가장 어려웠던 점?
- [ ] 핵심 성과 3가지?
- [ ] 실무 적용 방안?
- [ ] 한계와 개선 방안?
- [ ] 기술 스택 선택 이유?
- [ ] 동적 vs 정적 혼잡도?
- [ ] GEE를 선택한 이유?
- [ ] Cohen's h가 small인데 괜찮은가?

### ✅ 준비해야 할 자료

- [ ] GitHub 저장소 (코드 공개)
- [ ] 대시보드 데모 (localhost 또는 배포)
- [ ] 주요 차트 3-4개 (면접 시 화면 공유)
- [ ] 1페이지 요약 문서 (PDF)

---

## 마지막 조언

### 면접 답변 3원칙

1. **STAR 기법**:
   - **S**ituation: "이 프로젝트는 지하철 앱 UI 설계를 위한 A/B Test입니다"
   - **T**ask: "동적 피드백 시스템을 구현해야 했습니다"
   - **A**ction: "순차 처리 구조로 변경하고 CONGESTION_MULTIPLIER를 튜닝했습니다"
   - **R**esult: "목표 70-75%를 달성하고, 통계적 유의성을 확인했습니다"

2. **수치로 말하기**:
   - ❌ "Fast 선택률이 높았습니다"
   - ✅ "Fast 선택률이 71.18%로 목표 범위(70-75%)에 도달했습니다"

3. **솔직함**:
   - 모르는 건 솔직히 인정
   - "좋은 질문입니다. 저는 X까지 고려했는데, Y는 생각 못 했네요. 실무에서는 Y도 중요할 것 같습니다"

### 자신감을 갖는 법

- **당신은 6일 동안 완전한 파이프라인을 구축했습니다**
- **50만 rows 데이터를 생성하고 분석했습니다**
- **동적 시스템을 설계하고 구현했습니다**
- **8개 전문 차트와 대시보드를 완성했습니다**
- **통계적 엄밀성을 갖췄습니다 (GEE, FDR)**

이 프로젝트는 **실무 수준**이며, 많은 데이터 분석가들도 하지 못하는 **반복 측정 분석**과 **동적 시뮬레이션**을 구현했습니다.

---

**이 문서를 3번 이상 읽고, 예상 질문 60개에 답변 연습을 하면, 면접에서 어떤 질문이 나와도 자신있게 답변할 수 있을 것입니다!**

**행운을 빕니다! 🍀**
